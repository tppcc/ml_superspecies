#! /usr/bin/env python

"""
OpenLE - extract meteo files from ECMWF archive.

Run this script on ECMWF member state server (ecgate).


BATCH JOB

    Example of batch job on ecgate:
    
        #! /bin/sh

        #SBATCH --job-name=openle-gfas
        #SBATCH --qos=normal
        #SBATCH --workdir=/scratch/ms/xx/you/OpenLE
        #SBATCH --output=openle-gfas.out
        #SBATCH --error=openle-gfas.err
        #SBATCH --time=1-00:00:00

        # run:
        ${HOME}/OpenLE/bin/OpenLE-gfas


MARS ARCHIVE

    Meteo is archived in hypercubes with output from a single simulation.
    Data should be retrieved as much as possible per hypercube,
    thus perferably a loop over simulations than a loop over variables.

    The structure of the archive is shown in online manual:
      software.ecmwf.int  >  Site Space "User Documentation"
        MARS user documentation  >  MARS actions  >  Retrieve  >  Data collocation
    (https://software.ecmwf.int/wiki/display/UDOC/Retrieve#Retrieve-Datacollocation)

       class:                od
                              |
       stream:              oper
                              |
       expver:              0001
                          /      \
       type:            fc        an
                         |
       year:           yyyy     
       month:           mm      
                     /      \
       levtype:   sfc        ml
                   |
       date:      yyyymmdd
                    /  \
       time:      00    12
                   |     |
                 cube   cube
       
    Example of mars retrieval command:
      
        retrieve, 
            class    = mc, 
            stream   = oper, 
            expver   = 0001, 
            type     = ga, 
            levtype  = sfc, 
            date     = 20120710, 
            time     = 00,
            step     = 0-24, 
           [levels   = off,]
            grid     = off, 
            param    = co2fire, 
            target   = "mc-gfas-0001-ga-sfc-20120710-R0.1x0.1-co2fire.gb"

    Useful settings for some of the keywords:

        grid:
            F160      : regular              Gaussian grid
            N320      : 'normal'     reduced Guassian grid
            O640      : 'octahedral' reduced Gaussian grid
            1.0/1.0   : regular lon/lat


CONVERSION TO NETCDF

    The 'grib_to_netcdf' tool is used for conversion from grib to netcdf.
    Note that this tool only works for regular grids.
 
    The fire emissions in the test data set provided with OpenLE were produced
    using CDO for the grib-to-netcdf conversion; this conversion produces a
    different time stamp (24:00) than the 'grib_to_netcdf' conversion (00:00).
    
CF-COMPLIANCE

    The NetCDF files should be fed to a checker for CF compliance:
        http://puma.nerc.ac.uk/cgi-bin/cf-checker.pl

POST PROCESSING

    The following post-processing are applied:
    - Add boundaries for lon/lat cells.
    - Gather grid cells with fires into 1D arrays.

"""

#-------------------------------------------------
# modules
#-------------------------------------------------

# modules:
import os
import sys
import datetime
import calendar
import subprocess

# path to scripts:
openledir = os.path.join( os.environ['HOME'], 'work', 'le', 'OpenLE' )

# extend search path:
sys.path.insert( 0, os.path.join(openledir,'bin') )

# tools:
import rc
import leip_build
import c3po


#-------------------------------------------------
# settings
#-------------------------------------------------

# rcfile with settings for building source code.
rcfile = os.path.join( openledir, 'rc', 'openle-meteo.rc' )

# run directory:
rundir = os.path.join( os.environ['SCRATCH'], 'OpenLE', 'meteo' )

# remove temporary files ?
cleanup = True   # default
#cleanup = False  # testing ...

# run mars command? False for testing grib-to-netcdf:
with_mars = True   # default
#with_mars = False  # testing ...

# ***

# date range:
days = [ datetime.datetime(2012, 8,12), datetime.datetime(2012, 8,22) ]

# date range defined in job creation script:
#tfmt = '%Y-%m-%d'
#days = [ datetime.datetime.strptime(os.environ['DATE1'],tfmt), datetime.datetime.strptime(os.environ['DATE2'],tfmt) ]

# ***

# number of days per retrieval, None for monthly;
days_per_retrieval = { 'fc' : None }

# meteo dataset:
ec_class   = 'mc'
ec_stream  = 'gfas'
ec_expver  = '0001'

# forecast times and steps, keyword for target files:
ec_time = '00' ; ec_step = '0-24' ; tres = '1d'

# target grid:
ec_grid  = 'R0.10x0.10'   # global regular grid
# retrieve global grid first, otherwise mars will interpolate:
xx_grid = 'off'

# area selection N/W/S/E (only possible for regular grids!)
ec_area  = '78/-46/26/84' ; domain = 'europe_w46e84n26n78'
# global grid from mars:
xx_area  = 'global'

# basename for target files; keys:
#   %{domain}    : expanded before creation of mars script
#   YYYY         : expanded by post-processing
#   __           : future path seperation
target_template = '%{domain}__ECMWF__%{class}__gfas__%{expver}__%{type}__%{levtype}__%{grid}__YYYY__FIRE_[date]_%{tres}'

# parameters, define lists following archive structure:
#   params[type][levtype]
params = {}
params['ga'] = {}
params['ga']['sfc'] = ['210080','210081','210082','210083','210084','210085','210086','210087','210088','210089','210090','210091','210102','210103','210104','210105','210106','210107','210108','210109','210110','210111','210112','210113','210114','210115','210116','210117','210118','210231','210232','210233','210234','210235','210236','210237','210238','210239','210240','210241'] # tracers
params['ga']['sfc'].extend(['210119','210120']) # heights

# source parameters:
sparams = {}
#sparams['orog'] = 'z'   # will be converted from geopotential ("z") to surface altitude ("orog")

# translation to grib mars abbreviation:
gparams = {}
#gparams['t2m' ] = '2T'

# grib codes as expanded from '[param]' by mars:
gcodes = {}
for param in params['ga']['sfc'] :
    # split '210080' into parts:
    tabnr = int(param[0:3])
    parnr = int(param[3:6])
    # set grib code:
    gcodes[param] = '%i.%i' % (parnr,tabnr)
#endfor



#-------------------------------------------------
# begin
#-------------------------------------------------

# info ...
print( '' )
print( '** OpenLE gfas extract' )
print( '' )

# info ...
print( 'goto rundir : %s' % rundir )
# current location:
cwd = os.getcwd()
# create if necessary:
if not os.path.isdir(rundir) : os.makedirs( rundir )
# goto:
os.chdir( rundir )

# *

# ensure consisting naming of target files:
os.environ['MARS_MULTITARGET_STRICT_FORMAT'] = '1'

# set flag to build executable if necessary:
isbuild = False

# info ...
print( 'loop over types ...' )
# loop over types (an,fc):
for ec_type in params.keys() :
    # info ...
    print( '  type "%s" ...' % ec_type )

    # init list of (start,end) days per month:
    mdays = []
    # days per retrieval:
    if ec_type in days_per_retrieval.keys() :
        dpr = days_per_retrieval[ec_type]
    else :
        dpr = None  # monthly
    #endif
    # first:
    day1 = days[0]
    # loop:
    while day1 <= days[1] :
        # number of days per month:
        weekday,nday = calendar.monthrange(day1.year,day1.month)
        # end of month:
        eom = datetime.datetime(day1.year,day1.month,nday)
        # limited number of days? otherwise monthly:
        if dpr is None :
            # set end day:
            day2 = eom
        else :
            # step, not over end of month:
            day2 = min( day1 + datetime.timedelta(dpr-1), eom )
        #endif
        # truncate to overall range:
        day2 = min( day2, days[1] )
        # store:
        mdays.append( (day1,day2) )
        # next:
        day1 = day2 + datetime.timedelta(1)
    #endwhile # month loop

    # month loop:
    for day1,day2 in mdays :

        # info ...
        tfmt = '%Y-%m-%d'
        if day2 > day1 :
            print( '    date range: %s - %s' % (day1.strftime(tfmt),day2.strftime(tfmt)) )
        else :
            print( '    date: %s' % day1.strftime(tfmt) )
        #endif

        # date(s):
        tfmt = '%Y%m%d'
        if day2 > day1 :
            ec_date = '%s/to/%s' % (day1.strftime(tfmt),day2.strftime(tfmt))
        else :
            ec_date = '%s' % day1.strftime(tfmt)
        #endif

        # single record for some constant fields:
        if ec_type == 'xx' :
            xx_type = 'an'
            xx_time = '00'
            xx_step = None
        else :
            xx_type = ec_type
            xx_time = ec_time
            xx_step = ec_step
        #endif

        # loop over leveltypes:
        for ec_levtype in params[ec_type].keys() :
            # info ...
            print( '      levtype "%s" ...' % ec_levtype )
            
            # * mars
            
            # info ...
            print( '        mars ...' )

            # levels:
            if ec_levtype == 'sfc' :
                ec_levels = None
            else :
                ec_levels = levels
            #endif

            # parameters:
            ec_param = ''
            for param in params[ec_type][ec_levtype] :
                # seperation in list:
                sep = ''
                if len(ec_param) > 0 : sep = '/'
                # source params:
                sparam = param
                if param in sparams.keys() : sparam = sparams[param]
                # translate ?
                gparam = sparam
                if sparam in gparams.keys() : gparam = gparams[sparam]
                # add to list:
                ec_param = ec_param+sep+gparam
            #endif

            # target name; expand retrieval keywords to individual files:
            ec_target = target_template+'.gb'
            ec_target = ec_target.replace( '%{domain}' , domain     )
            ec_target = ec_target.replace( '%{class}'  , ec_class   )
            ec_target = ec_target.replace( '%{stream}' , ec_stream  )
            ec_target = ec_target.replace( '%{expver}' , ec_expver  )
            ec_target = ec_target.replace( '%{type}'   , xx_type    )
            ec_target = ec_target.replace( '%{levtype}', ec_levtype )
            ec_target = ec_target.replace( '%{grid}'   , ec_grid    )
            if ec_type == 'xx' :
                ec_target = ec_target.replace( 'YYYY'    , '0000' )
                ec_target = ec_target.replace( '_[date]' , '' )
                ec_target = ec_target.replace( '_%{tres}', '' )
            else :
                ec_target = ec_target.replace( '%{tres}' , tres )
            #endif

            # init mars job:
            lines = ['retrieve,']
            lines.append( 'class    = %s,' % ec_class   )
            lines.append( 'stream   = %s,' % ec_stream  )
            lines.append( 'expver   = %s,' % ec_expver  )
            lines.append( 'type     = %s,' % xx_type    )
            lines.append( 'levtype  = %s,' % ec_levtype )
            lines.append( 'date     = %s,' % ec_date    )
            lines.append( 'time     = %s,' % xx_time    )
            if xx_step is not None :
                lines.append( 'step     = %s,' % xx_step    )
            #endif
            if ec_levels is not None :
                lines.append( 'levels   = %s,' % ec_levels  )
            #endif
            lines.append( 'grid     = %s,' % xx_grid    )
            lines.append( 'area     = %s,' % xx_area    )
            lines.append( 'param    = %s,' % ec_param   )
            lines.append( 'target   = "%s"'  % ec_target  )
            
            # form line for history attribute:
            hline = '%s mars:' % datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S')
            for line in lines :
                hline = hline+(' '+line.replace(' ',''))
            #endfor

            # mars job file:
            marsjb = 'mars.jb'
            # write mars job:
            f = open( marsjb, 'w' )
            for line in lines : f.write( line+'\n' )
            f.close()

            # retrieval command:
            command = [ 'mars', marsjb ]
            # run?
            if with_mars :
                subprocess.check_call( command )
            #endif

            # cleanup?
            if cleanup : os.remove( marsjb )

            # * postprocessing
            
            # info ...
            print( '        postprocessing ...' )

            # loop over dates:
            day = day1
            while day <= day2 :
                # formated:
                syear = day.strftime('%Y')
                sdate = day.strftime('%Y%m%d')

                # grib file, has grib code as param name:
                gbfile = ec_target
                gbfile = gbfile.replace('[date]',sdate)
                #gbfile = gbfile.replace('[param]',gcode)

                # info ...
                print( '          convert "%s" to netcdf ...' % gbfile )

                # skip if not present (anymore):
                if not os.path.isfile(gbfile) :
                    print( '            grib file not present (anymore), continue ...' )
                    continue
                #endif

                # target file with parameter name:
                ncfile = ec_target
                ncfile = ncfile.replace('YYYY',syear)
                ncfile = ncfile.replace('[date]',sdate)
                ncfile = ncfile.replace('.gb','.nc')

                # reference date at start of year:
                refdate = '%4.4i0101' % day.year
                # conversion tool ;
                # define time to be unlimitted (useful for nco tools);
                # use datatype double to avoid packing,
                # data needs to be gathered so zero values should remain:
                command = [ 'grib_to_netcdf', '-R', refdate, '-u', 'time',
                                '-D', 'NC_DOUBLE', '-o', ncfile, gbfile ]
                # run:
                subprocess.check_call( command )

                # info ...
                print( '          add mars command to history ...' )

                # use NCO attribute editor to add mars command to history;
                # do not add this command itself to the history ...
                command = [ 'ncatted', '-h', '-a', 'history,global,a,c,"\n%s"' % hline, ncfile ]
                # run:
                subprocess.check_call( command )

                # info ...
                print( '          gather ...' )
                # open existing file for read/write:
                ecfile = c3po.ecmwf.ncfile.EcGridFile( ncfile )
                # add boundary values:
                ecfile.AddBounds( 'longitude' )
                ecfile.AddBounds( 'latitude'  )
                # gather values into 1D arrays:
                ecfile.Gather( cleanup=cleanup )
                # close:
                ecfile.close()

                # cleanup ?
                if cleanup :
                    # info ...
                    print( '          cleanup: %s ...' % gbfile )
                    # remove gribfile:
                    os.remove( gbfile )
                    # coarsened file present ?
                #endif

                # next:
                day = day + datetime.timedelta(1)
            #endwhile # days

            # *
            
            ## testing ...
            #break

        #endfor  # month loop
        
        ## testing ...
        #break
        
    #endfor # levtype
    
    ## testing ...
    #break

#endfor # type

# info ...
print( 'back to %s ...' % cwd )
# back:
os.chdir( cwd )

# info ..
print( '' )
print( '** end' )
print( '' )


#-------------------------------------------------
# end
#-------------------------------------------------

