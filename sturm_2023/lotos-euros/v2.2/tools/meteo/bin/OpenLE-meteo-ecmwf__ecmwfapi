#! /usr/bin/env python3

"""
OpenLE - extract meteo files from ECMWF archive.


WHERE TO RUN

  Where to run this script?
  
  - On ECMWF member state server.
  
  - On local server:
  
    - Using ECMWF Web API (only for public datasets?)
    
        https://software.ecmwf.int/wiki/display/WEBAPI/Access+ECMWF+Public+Datasets
        
      Requests to the Web API require extra keywords:
      - Define the "dataset", see:
          https://software.ecmwf.int/wiki/display/WEBAPI/Available+ECMWF+Public+Datasets
      - For the output format:
          'format' : 'netcdf' 

    - Using a local version of the MARS command:

        https://software.ecmwf.int/wiki/display/WEBAPI/Access+MARS


MARS ARCHIVE

    Meteo is archived in hypercubes with output from a single simulation.
    Data should be retrieved as much as possible per hypercube,
    thus perferably a loop over simulations than a loop over variables.

    The structure of the archive is shown in online manual:
      software.ecmwf.int  >  Site Space "User Documentation"
        MARS user documentation  >  MARS actions  >  Retrieve  >  Data collocation
    (https://software.ecmwf.int/wiki/display/UDOC/Retrieve#Retrieve-Datacollocation)

       class:                od
                              |
       stream:              oper
                              |
       expver:              0001
                          /      \
       type:            fc        an
                         |
       year:           yyyy     
       month:           mm      
                     /      \
       levtype:   sfc        ml
                   |
       date:      yyyymmdd
                    /  \
       time:      00    12
                   |     |
                 cube   cube
       
    Example of mars retrieval command:
      
        retrieve, 
            class    = od, 
            stream   = oper, 
            expver   = 0001, 
            type     = fc, 
            levtype  = sfc, 
            date     = 20120710, 
            time     = 00/12,
            step     = 03/06/09/12, 
           [levels   = off,]
            grid     = F160, 
            param    = t2m, 
            target   = "od-oper-0001-fc-sfc-20120710-F160-t2m.gb"

    Useful settings for some of the keywords:

        grid:
            F160      : regular              Gaussian grid
            N320      : 'normal'     reduced Guassian grid
            O640      : 'octahedral' reduced Gaussian grid
            1.0/1.0   : regular lon/lat


CONVERSION TO NETCDF

    The 'grib_to_netcdf' tool is used for conversion from grib to netcdf.
    Note that this tool only works for regular grids.
    
    
CF-COMPLIANCE

    The NetCDF files should be fed to a checker for CF compliance:
        http://puma.nerc.ac.uk/cgi-bin/cf-checker.pl

    The following errata were found:
    - Unsupported units:
      - Land sea mask (lsm), soil type (slt), sea ice (ci), cloud cover (cc)
        units "(0 - 1)" should be "1"
      - Soil type (slt)
        units "~" should be "1"
      - Snow depth (sd), Snowfall (sf)
        units "m of water equivalent" should "m"
    - Model level files lack hybride coefficients;
      also surface pressure field is missing initially.
      These are added from other files:
      - surface pressure file is created from original log-surface pressure
        (on model levels, only log-surface pressure is in archive)
      - hybride coefficients are copied from log-surface pressure file
        that is converted from grib to netcdf by cdo

POST PROCESSING

    The following post-processing are applied:
    - Accumulated fields are transformed to averages over time interval
    - Model levels are coarsened to about 20 in the troposphere.


BATCH JOB ON MEMBER STATE SERVER

    Example of batch job on ecgate:
    
        #! /bin/sh

        #SBATCH --job-name=openle-meteo
        #SBATCH --qos=normal
        #SBATCH --workdir=/scratch/ms/xx/you/OpenLE
        #SBATCH --output=openle-meteo.out
        #SBATCH --error=openle-meteo.err
        #SBATCH --time=1-00:00:00

        # run:
        ${HOME}/OpenLE/bin/OpenLE-meteo-ecmwf



"""

#-------------------------------------------------
# modules
#-------------------------------------------------

# modules:
import os
import sys
import datetime
import calendar
import subprocess

# path to scripts:
tools_meteo_dir = os.getcwd()

# extend search path:
sys.path.insert( 0, os.path.join(tools_meteo_dir,'bin') )

# tools:
import rc
import leip_build
import c3po


#-------------------------------------------------
# settings
#-------------------------------------------------

# run directory:
rundir = os.path.join( os.environ['SCRATCH'], 'OpenLE', 'meteo' )
#rundir = '/daten/ECMWF/westafrica/'
#rundir = '/daten/ECMWF/southafrica/'
#rundir = '/daten/ECMWF/westafrica_2015-2017/'
#rundir = '/daten/ECMWF/white_sands_10.2017/'
#rundir = '/daten/ECMWF/test/'

# renew existing files?
renew = True   # default
#renew = False  # testing ...

# remove temporary files ?
cleanup = True   # default
#cleanup = False  # testing ...

# archive results?
archive = True
# destination:
archive_dir = os.path.join( rundir, 'ARCHIVE' )

# rcfile with settings for building source code.
rcfile = os.path.join( tools_meteo_dir, 'rc', 'openle-meteo.rc' )

# ***

# date range:
#days = [ datetime.datetime(2012, 6,30), datetime.datetime(2012, 7,31) ]
days = [ datetime.datetime(2017, 9, 25), datetime.datetime(2017, 9, 30) ]

# ***

# number of days per retrieval, None for monthly;
# use monthyly for analysis, 
# for forecast eventually limit if not enough space:
days_per_retrieval = { 'an' : None, 'fc' : None }

# meteo dataset:
ec_class   = 'od'   # operational data
#ec_class   = 'ea'   # ERA5 (public)

# atmosphere model:
ec_stream  = 'oper'
# default experiment:
ec_expver  = '0001'

# define dataset, see:
#   https://software.ecmwf.int/wiki/display/WEBAPI/Available+ECMWF+Public+Datasets
ec_datasets = {}
ec_datasets['od'] = None
ec_datasets['ei'] = 'interim'
ec_datasets['ea'] = 'era5'

# time resolution keys per level type:
tress = { 'sfc' : '1h', 'ml' : '3h' }
# forecast times and steps per keyword:
ec_times = {} ; ec_steps = {}
ec_times['3h'] = '00/12' ; ec_steps['3h'] = '03/06/09/12'
ec_times['1h'] = '00/12' ; ec_steps['1h'] = '01/02/03/04/05/06/07/08/09/10/11/12'


# target grid:
ec_grid  = 'F640'   # regular gaussian grid
#USE F640 for WESTAFRICA
#ec_grid = '0.25/0.25'
#ec_grid  = 'F320'   # era5 resolution is N320

# area selection N/W/S/E (only possible for regular grids!)
#ec_area  = '10/0/0/10' ; domain = 'test_w0e10n0n10'
#ec_area  = '75/-30/-5/70' ; domain = 'europe_w30e70s5n75'
#ec_area  = '40/-30/0/30'  ; domain = 'africa_w30e30n0n40'
#ec_area  = '-40/11.25/-20/42'  ; domain = 'africa_e12e42s20s40'
ec_area = '29/-111/35/-101' ; domain = 'withe_sands_w111w101n29n35'

# number of levels in ECMWF model for this time period:
#L = 60    # ei
#L = 91
L = 137  # od from 2014, era5

# model level range:
levels = '1/to/%i' % L

# coarsen levels to about 20 in troposphere,
# depends on original number of layers:
levcoarse = {}
levcoarse[137] = { 'name' : 'L137_CL42', 'coarsening' : '3/4/4/4/4/4/4/4/4/4/4/4/4/4/4/4/4/4/4/4/4/4/4/4/4/4/4/3/3/3/3/3/2/2/2/2/2/1/1/1/1/1' }

# basename for target files; keys:
#   %{domain}    : expanded before creation of mars script
#   [param]      : expanded by mars
#   YYYY         : expanded by post-processing
#   __           : future path seperation
#target_template = '%{domain}__ECMWF__%{class}__ifs__%{expver}__%{type}__%{levtype}__%{grid}__YYYY__[param]_[date]_%{tres}'
target_template = '%{domain}__ECMWF__%{class}__ifs__%{expver}__%{type}__%{levtype}__%{grid}__YYYY__PARAM_DATE_%{tres}.nc'

# parameters; define lists following archive structure:
#   params[type][levtype]
# names as produced by 'grib_to_netcdf', mars command might need translations in 'gparams':
params = {}
params['xx'] = {}
params['xx']['sfc'] = ['orog','lsm','slt']
params['an'] = {}
params['fc'] = {}
#params['fc']['sfc'] = ['blh','t2m','d2m','u10','v10','sst','ci','tcc','swvl1','swvl2','swvl3','swvl4','sd','ssr','ssrd','lsp','cp','sf']
params['fc']['sfc'] = ['blh','ci','cp','d2m','lsp','sd','sf','skt','slhf','sshf','ssr','ssrd','sstk','stl1','stl2','stl3','stl4','swvl1','swvl2','swvl3','swvl4','t2m','tcc','u10','v10','zust']
##params['fc']['sfc'] = ['sst']
#params['fc']['ml'] = ['t','q','u','v','cc','clwc']
#params['fc']['ml'] = ['t','q','u','v','cc']
params['fc']['ml'] = ['lnsp','cc','ciwc','clwc','crwc','cswc','q','t','u','v']

#params = {}
#params['xx'] = {}
#params['xx']['sfc'] = ['orog','lsm','slt']
#params['an'] = {}
#params['fc'] = {}
#params['fc']['sfc'] = ['blh','t2m','d2m','u10','v10','sstk','ci','swvl1','swvl2','swvl3','swvl4','sd','ssr','ssrd','lsp','cp','sf']
#params['fc']['ml'] = ['lnsp','t','q','u','v','cc','clwc']



# source parameters:
sparams = {}
sparams['orog'] = 'z'   # will be converted from geopotential ("z") to surface altitude ("orog")

# translation from (source) parameters to grib mars abbreviation:
gparams = {}
gparams['t2m' ] = '2t'
gparams['d2m' ] = '2d'
gparams['u10' ] = '10u'
gparams['v10' ] = '10v'

# accumulated fields:
accums = ['ssr','ssrd','lsp','cp','sf']

# standard names change after de-accumulation:
standard_names = {}
standard_names['sf' ] = 'lwe_snowfall_rate'
standard_names['lsp'] = 'lwe_stratiform_precipitation_rate'
standard_names['cp' ] = 'lwe_convective_precipitation_rate'


#-------------------------------------------------
# methods
#-------------------------------------------------

def MarsCall( mdict ) :

    """
    Call mars using dictionairy settings.
    
    Either uses the Python API (only for public datasets),
    or the MARS command downloaded from:
        https://software.ecmwf.int/wiki/display/WEBAPI/Access+MARS
    
    """
    
    # modules:
    import os
    import subprocess

    ## tools:
    #import ecmwfapi

    ## init:
    #server = ecmwfapi.ECMWFDataServer()
    ## retrieve:
    #server.retrieve( mdict )
    
    # job lines:
    line = 'retrieve'
    for key in mdict.keys() :
        line = line+(', %s = %s' % (key,mdict[key]))
    #endfor

    # target file:
    marsjb = 'mars.jb'
    
    # write:
    f = open( marsjb, 'w' )
    f.write( line+'\n' )
    f.close()

    # run:
    subprocess.check_call( ['mars',marsjb] )
    
    # clear:
    os.remove( marsjb )

#enddef MarsCall


#-------------------------------------------------
# begin
#-------------------------------------------------

# info ...
print( '' )
print( '** OpenLE meteo extract' )
print( '' )

# info ...
print( 'goto rundir : %s' % rundir )
# current location:
cwd = os.getcwd()
# create if necessary:
if not os.path.isdir(rundir) : os.makedirs( rundir )
# goto:
os.chdir( rundir )

# *

# set flag to build executable if necessary:
isbuild = False

# info ...
print( 'loop over types ...' )
# loop over types (an,fc):
for ec_type in params.keys() :
    # info ...
    print( '  type "%s" ...' % ec_type )

    # init list of (start,end) days per month:
    mdays = []
    # switch:
    if ec_type == 'xx' :
        # first day:
        mdays.append( (days[0],days[0]) )
    else :
        # days per retrieval:
        if ec_type in days_per_retrieval.keys() :
            dpr = days_per_retrieval[ec_type]
        else :
            dpr = None  # monthly
        #endif
        # first:
        day1 = days[0]
        # loop:
        while day1 <= days[1] :
            # number of days per month:
            weekday,nday = calendar.monthrange(day1.year,day1.month)
            # end of month:
            eom = datetime.datetime(day1.year,day1.month,nday)
            # limited number of days? otherwise monthly:
            if dpr is None :
                # set end day:
                day2 = eom
            else :
                # step, not over end of month:
                day2 = min( day1 + datetime.timedelta(dpr-1), eom )
            #endif
            # truncate to overall range:
            day2 = min( day2, days[1] )
            # store:
            mdays.append( (day1,day2) )
            # next:
            day1 = day2 + datetime.timedelta(1)
        #endwhile # month loop
    #endif # constant or timeseries

    # loop over day ranges:
    for day1,day2 in mdays :

        # info ...
        tfmt = '%Y-%m-%d'
        if day2 > day1 :
            print( '    date range: %s - %s' % (day1.strftime(tfmt),day2.strftime(tfmt)) )
        else :
            print( '    date: %s' % day1.strftime(tfmt) )
        #endif

        # date(s):
        tfmt = '%Y%m%d'
        if day2 > day1 :
            ec_date = '%s/to/%s' % (day1.strftime(tfmt),day2.strftime(tfmt))
        else :
            ec_date = '%s' % day1.strftime(tfmt)
        #endifd

        # by default no lnsp file needed ...
        lnsp_gbfile_ec = None
        lnsp_ncfile_ec = None

        # loop over leveltypes:
        for ec_levtype in params[ec_type].keys() :
            # info ...
            print( '      levtype "%s" ...' % ec_levtype )
            
            # check ...
            if ec_class not in ec_datasets.keys() :
                print( 'ERROR - no ecmwf dataset defined for class "%s"' % ec_class )
                raise Exception
            #endif
            # extract:
            ec_dataset = ec_datasets[ec_class]

            # levels:
            if ec_levtype == 'sfc' :
                ec_levels = None
            else :
                ec_levels = levels
            #endif

            # time resolution:
            tres = tress[ec_levtype]

            # single record for some constant fields:
            if ec_type == 'xx' :
                xx_type = 'an'
                xx_time = '00'
                xx_step = None
            else :
                xx_type = ec_type
                xx_time = ec_times[tres]
                xx_step = ec_steps[tres]
            #endif

            # parameters:
            ec_param = ''
            for param in params[ec_type][ec_levtype] :
                # seperation in list:
                sep = ''
                if len(ec_param) > 0 : sep = '/'
                # source params:
                sparam = param
                if param in sparams.keys() : sparam = sparams[param]
                # translate ?
                gparam = sparam
                if sparam in gparams.keys() : gparam = gparams[sparam]
                # add to list:
                ec_param = ec_param+sep+gparam
            #endif

            # target name; expand retrieval keywords to individual files:
            ec_target = target_template
            ec_target = ec_target.replace( '%{domain}' , domain     )
            ec_target = ec_target.replace( '%{class}'  , ec_class   )
            ec_target = ec_target.replace( '%{stream}' , ec_stream  )
            ec_target = ec_target.replace( '%{expver}' , ec_expver  )
            ec_target = ec_target.replace( '%{type}'   , xx_type    )
            ec_target = ec_target.replace( '%{levtype}', ec_levtype )
            ec_target = ec_target.replace( '%{grid}'   , ec_grid    )
            if ec_type == 'xx' :
                ec_target = ec_target.replace( 'YYYY'    , '0000' )
                ec_target = ec_target.replace( '_DATE' , '' )
                ec_target = ec_target.replace( '_%{tres}', '' )
            else :
                ec_target = ec_target.replace( '%{tres}' , tres )
            #endif

            # init mars job:
            marsdict = {}
            if ec_dataset is not None : marsdict['dataset'] = ec_dataset
            marsdict['class'  ] = ec_class
            marsdict['stream' ] = ec_stream
            marsdict['expver' ] = ec_expver
            marsdict['type'   ] = xx_type
            marsdict['levtype'] = ec_levtype
            marsdict['date'   ] = ec_date
            marsdict['time'   ] = xx_time
            if xx_step is not None :
                marsdict['step'] = xx_step
            #endif
            if ec_levels is not None :
                marsdict['levels'] = ec_levels
            #endif
            marsdict['grid'   ] = ec_grid
            marsdict['area'   ] = ec_area
            marsdict['param'  ] = ec_param
            marsdict['format' ] = 'netcdf'
            marsdict['target' ] = ec_target
            
            # retrieve?
            if renew or (not os.path.isfile(marsdict['target'])) :
                # info ...
                print( '        retrieve "%s" ...' % ec_target )
                print( '          retrieval dictionairy:' )
                for key in marsdict.keys() :
                    print( '            "%s" : "%s"' % (key,marsdict[key]) )
                #endfor
                # form line for history attribute:
                hline = '%s mars: retrieve' % datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S')
                for key in marsdict.keys() :
                    hline = hline+(', %s = %s' % (key,marsdict[key]))
                #endfor
                # not present yet?
                if not os.path.isfile(marsdict['target']) :
                    # retrieve:
                    MarsCall( marsdict )
                #endif
                # use NCO attribute editor to add mars command to history;
                # do not add this command itself to the history ...
                command = [ 'ncatted', '-h', '-a', 'history,global,a,c,"\n%s"' % hline, ec_target ]
                # run:
                subprocess.check_call( command )
            else :
                # info ...
                print( '        keep existing "%s" ...' % ec_target )
            #endif

            # adhoc: need grib file with lnsp, 
            # to use 'cdo' to convert while maintaining hybride coeffs ...
            if ec_levtype == 'ml' :
                # target file:
                #lnsp_gbfile_ec = marsdict['target'].replace('PARAM','lnsp').replace('.nc','.gb')
                lnsp_ncfile_ec = marsdict['target'].replace('PARAM','lnsp')
                # replace some keys:
                marsdict['param' ] = 'lnsp'
                marsdict['levels'] = '1'
                marsdict['target'] = lnsp_ncfile_ec
                # not present yet?
                if renew or (not os.path.isfile(marsdict['target'])) :
                    # info ...
                    print( '        retrieve "%s" ...' %  marsdict['target'] )
                    print( '          retrieval dictionairy:' )
                    for key in marsdict.keys() :
                        print( '            "%s" : "%s"' % (key,marsdict[key]) )
                    #endfor
                    # retrieve:
                    MarsCall( marsdict )
                else :
                    # info ..
                    print( '        keep existing "%s" ...' %  marsdict['target'] )
                #endif
            #endif


            # * postprocessing
            
            # info ...
            print( '        postprocessing ...' )

            # number of times:
            ntime = len(xx_time.split('/'))
            # number of steps:
            if xx_step is None :
                nstep = 1
            else :
                nstep = len(xx_step.split('/'))
            #endif
            # number of records:
            nrec = ntime * nstep

            # init day counter:
            iday = 0
            # loop over dates:
            day = day1
            while day <= day2 :
            
                # info ..
                print( '          day %s ...' % day.strftime('%Y-%m-%d') )
                
                # next:
                iday = iday + 1
                # record range (zero based):
                irec1 = (iday-1)*nrec
                irec2 = irec1 + nrec - 1
                
                # intermediate files:
                lnsp_ncfile = None
                sp_ncfile   = None
                
                # loop over parameters:
                for param in params[ec_type][ec_levtype] :
            
                    # info ..
                    print( '            param %s ...' % param )
                    
                    # source param:
                    sparam = param
                    if param in sparams.keys() : sparam = sparams[param]

                    # target file for single param and day:
                    print('I am here')
                    ncfile = ec_target
                    ncfile = ncfile.replace( 'PARAM', sparam )
                    ncfile = ncfile.replace( 'YYYY', day.strftime('%Y') )
                    ncfile = ncfile.replace( 'DATE', day.strftime('%Y%m%d') )
                    
                    # extract?
                    if renew or (not os.path.isfile(ncfile)) :
                        # info ..
                        print( '              create %s ...' % ncfile )                    
                        # extract command:
                        command = [ 'ncks', '-v', sparam, '-d', 'time,%i,%i' % (irec1,irec2), \
                                      '-O', ec_target, ncfile ]
                        # run:
                        subprocess.check_call( command )
                    else :
                        # info ..
                        print( '              target file %s already present ...' % ncfile )  
                    #endif

                    # convert?
                    if param == 'orog' :
                        # info ...
                        print( '          compute orog = z/g ...' )
                        # Convert from geopotential to surface altitude:
                        #    orog = z / 9.8   # devide by standard gravitiy acceleration
                        # Use NCO arithmatic processor (ncap, ncap2 does not work properly?);
                        # first create algebra:
                        algebra = 'orog=pack(z/9.8)'
                        algebra = algebra+';orog@units="m"'
                        algebra = algebra+';orog@long_name="Surface altitude"'
                        algebra = algebra+';orog@standard_name="surface_altitude"'
                        # source file with source param name:
                        ncfile_in = ncfile
                        # target file with final param name:
                        ncfile = ec_target
                        ncfile = ncfile.replace( 'PARAM', param )
                        ncfile = ncfile.replace( 'YYYY', day.strftime('%Y') )
                        ncfile = ncfile.replace( 'DATE', day.strftime('%Y%m%d') )
                        # command, only keep new variables:
                        subprocess.check_call( [ 'ncap', '-O', '-v', '-s', algebra, ncfile_in, ncfile ] )
                        # cleanup?
                        if cleanup : 
                            print( '          remove %s ...' % ncfile_in )
                            os.remove( ncfile_in )
                        #endif
                    #endif

                    # remove useless time dimension from constant files:
                    if param in ['orog','lsm','slt'] :
                        # weighter average removes dimension:
                        subprocess.check_call( [ 'ncwa', '-O', '-a', 'time', ncfile, ncfile ] )
                        # remove time variable:
                        subprocess.check_call( [ 'ncks', '-O', '-x', '-v', 'time', ncfile, ncfile ] )
                    #endif

                    # change units?
                    # ~ '(0 - 1)' to '1'
                    if param in ['lsm','slt','ci','cc'] :
                        # new units:
                        units     = '1'
                        # info ...
                        print( '              reset units to "%s" ...' % units )
                        # use NCO attribute editor to overwrite units:
                        try :
                            subprocess.check_call( [ 'ncatted', '-a', 'units,%s,o,c,%s' % (param,units), ncfile ] )
                        except :
                            # "ci" is sometimes named "siconc" ...
                            if param == 'ci' :
                                param2 = 'siconc'
                                subprocess.check_call( [ 'ncrename', '-v', '%s,%s' % (param2,param), ncfile ] )
                                subprocess.check_call( [ 'ncatted', '-a', 'units,%s,o,c,%s' % (param,units), ncfile ] )
                            #endif
                        #endtry
                        # use NCO attribute editor to overwrite units:
                        subprocess.check_call( [ 'ncatted', '-a', 'units,%s,o,c,%s' % (param,units), ncfile ] )
                    #endif
                    # ~ 'm of water equivalent' to 'm'
                    if param in ['sd','sf'] :
                        # new units:
                        units = 'm'
                        # info ...
                        print( '              reset units to "%s" ...' % units )
                        # use NCO attribute editor to overwrite units:
                        subprocess.check_call( [ 'ncatted', '-a', 'units,%s,o,c,%s' % (param,units), ncfile ] )
                    #endif

                    # accumulated field ?
                    if param in accums :

                        # info ...
                        print( '              de-accumulate ...' )
                        # open existing file for read/write:
                        ecfile = c3po.ecmwf.ncfile.EcGridFile( ncfile )
                        # convert from accumulated to temporal avarge fields:
                        ecfile.DeAccum( '%s, step=%s' % (xx_time,xx_step) )
                        # close:
                        ecfile.close()
                        
                        # replace?
                        if param in standard_names.keys() :
                            # info ...
                            print( '              reset standard name to "%s" ...' % standard_names[param] )
                            # reset standard name:
                            subprocess.check_call( [ 'ncatted', '-a', 'standard_name,%s,o,c,%s' % (param,standard_names[param]), ncfile ] )
                        #endif

                    #endif
                    
                    # fix level definition?
                    if ec_levtype == 'ml' :
                        # info ...
                        print( '              fix level definition ...' )

                        # target file for single param and day:
                        lnsp_ncfile = lnsp_ncfile_ec
                        lnsp_ncfile = lnsp_ncfile.replace( 'PARAM', 'lnsp' )
                        lnsp_ncfile = lnsp_ncfile.replace( 'YYYY', day.strftime('%Y') )
                        lnsp_ncfile = lnsp_ncfile.replace( 'DATE', day.strftime('%Y%m%d') )
                        # extract?
                        if renew or (not os.path.isfile(lnsp_ncfile)) :
                            # info ..
                            print( '                create %s ...' % lnsp_ncfile )                    
                            # extract command:
                            command = [ 'ncks', '-O', '-d', 'time,%i,%i' % (irec1,irec2), lnsp_ncfile_ec, lnsp_ncfile ]
                            # run:
                            subprocess.check_call( command )
                        else :
                            # info ..
                            print( '                keep existing %s ...' % lnsp_ncfile )      
                        #endif

                        # convert from log-surface-pressure to surface pressure;
                        # name of surface pressure variable:
                        spvar = 'sp'
                        # target file:
                        sp_ncfile = lnsp_ncfile.replace('lnsp',spvar)
                        # not present yet ?
                        if renew or (not os.path.isfile(sp_ncfile)) :
                            # info ...
                            print( '                create %s ...' % sp_ncfile )
                            # Use NCO arithmatic processor;
                            # ncap2 does not seem to work properly, use ncap;
                            # create algebra:
                            algebra = '%s=pack(exp(lnsp))' % spvar
                            algebra = algebra+';%s@units="Pa"' % spvar
                            algebra = algebra+';%s@long_name="Surface air pressure"' % spvar
                            algebra = algebra+';%s@standard_name="surface_air_pressure"' % spvar
                            # command:
                            command = [ 'ncap', '-O', '-s', algebra, lnsp_ncfile, sp_ncfile ]
                            # run:
                            subprocess.check_call( command )
                        else :
                            # info ...
                            print( '                keep existing %s ...' % sp_ncfile )
                        #endif
                        
                        # info ...
                        print( '                add surface pressure ...' )
                        # run:
                        subprocess.check_call( [ 'ncks', '-A', '-v', spvar, sp_ncfile, ncfile ] )
 
                        #endif
                        
                        # source file with level coefficients:
                        levelfile = os.path.join( tools_meteo_dir, 'data', 'ECMWF-L%i.nc' % L )
                        # info ...
                        print( '                copy hybride level variables from %s ...' % levelfile )
                        # run:
                        subprocess.check_call( [ 'ncks', '-A', '-C', '-v', 'level,hyam,hybm,hlevel,hyai,hybi', levelfile, ncfile ] )

                        # info ...
                        print( '          coarsen levels ...' )
                        # build ?
                        if not isbuild :
                            # set environment used in settings:
                            os.environ['TOOLS_METEO_DIR'] = tools_meteo_dir
                            os.environ['WORK_DIR'] = os.getcwd()
                            # read settings:
                            rcf = rc.RcFile( rcfile )
                            # build program to coarsen levels:
                            coarselevs_x = leip_build.Build( rcf, 'coarselevs' )
                            # reset flag:
                            isbuild = True
                        #endif
                        # coarsen levels:
                        clevs_name       = levcoarse[L]['name']
                        clevs_coarsening = levcoarse[L]['coarsening']
                        # target file:
                        ncfile_clevs = ncfile.replace('_ml_','_'+clevs_name+'_')
                        # command for external executable:
                        command = [ coarselevs_x, 'level', 'hlevel', clevs_coarsening, ncfile, ncfile_clevs ]
                        # run:
                        subprocess.check_call( command )
                        
                        # cleanup?
                        if cleanup :
                            # info ...
                            print( '          cleanup: %s ...' % ncfile )
                            # remove version with original levels:
                            os.remove( ncfile )
                        #endif
                        
                        # reset target file name:
                        ncfile = ncfile_clevs
                        
                    #endif # model levels?
                    
                    # remove fill values, often incorrect type and cf-checker complains:
                    subprocess.check_call( [ 'ncatted', '-a', '_FillValue,%s,d,,' % param, ncfile ] )
                    
                    # pack:
                    subprocess.check_call( [ 'ncpdq', '-O', ncfile, ncfile ] )
                    
                    # archive?
                    if archive :
                        # full path to target file;
                        # replace '__' by path seperation:
                        afile = os.path.join( archive_dir, ncfile.replace('__',os.path.sep) )
                        # target dir:
                        adir = os.path.dirname( afile )
                        # create if necessary:
                        if not os.path.isdir(adir) : os.makedirs( adir )
                        # info ...
                        print( '          archive into %s ...' % afile )
                        # move:
                        os.rename( ncfile, afile )
                    #endif
                    
                #endfor # params
                    
                # cleanup lnsp files, used for multiple ml files :
                if cleanup :
                    # loop:
                    for fname in [lnsp_ncfile,sp_ncfile] :
                        # defined?
                        if fname is None : continue
                        # present?
                        if os.path.isfile(fname) :
                            # info ...
                            print( '          cleanup: %s ...' % fname )
                            # remove gribfile:
                            os.remove( fname )
                        #endif
                    #endif
                #endif

                # next:
                day = day + datetime.timedelta(1)
            #endwhile # days
                    
            # cleanup files with all data:
            if cleanup :
                # loop:
                for fname in [ec_target,lnsp_gbfile_ec,lnsp_ncfile_ec] :
                    # skip?
                    if fname is None : continue
                    # present?
                    if os.path.isfile(fname) :
                        # info ...
                        print( '          cleanup: %s ...' % fname )
                        # remove gribfile:
                        os.remove( fname )
                    #endif
                #endif
            #endif

            # *
            
            ## testing ...
            #break

        #endfor  # level types
        
        ## testing ...
        #break
        
    #endfor # date ranges
    
    ## testing ...
    #break

#endfor # type

# info ...
print( '' )
print( 'back to %s ...' % cwd )
# back:
os.chdir( cwd )

# info ..
print( '' )
print( '** end' )
print( '' )


#-------------------------------------------------
# end
#-------------------------------------------------

